{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe37d626-2251-45d4-a7dd-763d14e225a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f838e-fc64-4911-abe3-bbecf8bd5e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, Model, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1157da6-8221-4e49-a6ea-c2b70ba29153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os for stuff\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection  import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# to supress invalid warning \n",
    "old_err_state = np.seterr(invalid ='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba07f22-985f-4995-a382-2d03a812cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk\n",
    "import nltk\n",
    "nltk.download(['stopwords','punkt'])\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "porterStemmer = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f747670e-ac84-423b-b67e-c1385722a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seop constant \n",
    "sep = '\\\\' if os.name == 'nt' else '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "485b7458-5ae9-4f56-ac15-72fccc113d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function\n",
    "def get_folder_list(path) :\n",
    "    # get list of dir from path\n",
    "    dir_list = None\n",
    "    for (root,dirs,files) in os.walk(path, topdown=True):\n",
    "        dir_list = dirs\n",
    "        break\n",
    "    return dir_list\n",
    "\n",
    "def get_file_list(path) :\n",
    "    # get list of file in path\n",
    "    file_list = None\n",
    "    for (root,dirs,files) in os.walk(path, topdown=True):\n",
    "        file_list = files\n",
    "        break\n",
    "    return file_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0f2390-79de-4e13-9f14-b34f0119bced",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97a63cf5-08ad-4a4c-87cc-8b4453b595c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_dataset_from_directory_to_dataframe(path) :\n",
    "    # return df\n",
    "    # text_dataset_from_directory function\n",
    "    \n",
    "    #dset_path = os.getcwd() + sep +\"data\"+sep+\"bbc\"\n",
    "    dset_path = path\n",
    "    dset_name = get_folder_list(dset_path)\n",
    "\n",
    "    # key  : class name    -> str\n",
    "    # value: list of files -> list of str\n",
    "    file_dict = dict()\n",
    "\n",
    "\n",
    "    # get list of dir from path\n",
    "    for class_name in dset_name :\n",
    "        class_path = dset_path + sep + class_name\n",
    "        file_dict[class_name] = get_file_list(class_path)\n",
    "        # print(get_file_list(class_path))\n",
    "\n",
    "    # print(file_dict)\n",
    "\n",
    "    # key   : class name -> str\n",
    "    # value : list of text -> list of str\n",
    "    text_dict = dict()\n",
    "\n",
    "\n",
    "    for class_name, f_name_list in file_dict.items():\n",
    "        # print(key, values)\n",
    "        # print(class_name)\n",
    "        # print(f_name_list)\n",
    "        # raw string\n",
    "        text_list = []\n",
    "        for txt_name in f_name_list :\n",
    "            # print(txt_name)\n",
    "            # print(class_name)\n",
    "            f_path = dset_path + sep + class_name + sep + txt_name\n",
    "            with open(f_path ,'r') as f :\n",
    "                ## \\n\\n will be .\n",
    "                tt = re.sub('\\n\\n', '.', f.read())\n",
    "                text_list.append(tt)\n",
    "\n",
    "        text_dict[class_name] = text_list\n",
    "\n",
    "    # print(text_dict)\n",
    "\n",
    "    # list of tuple -> (text, label)\n",
    "    zipped_list = []\n",
    "    for class_name, text_list in text_dict.items() :\n",
    "        temp = list(zip(text_list, [class_name]*len(text_list)))\n",
    "        # print(temp[:3])\n",
    "        zipped_list = zipped_list + temp\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(zipped_list, columns=['text', 'label'])\n",
    "    \n",
    "    return df\n",
    "    # t = dset_path + sep + dset_name[0] + sep + '001.txt'\n",
    "    # with open(t,'r') as f :\n",
    "    #     txt = f.read()\n",
    "\n",
    "    # print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e681f8ab-9075-47bd-8bf7-d74ef1b83c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.getcwd() + sep +\"data\"+sep+\"bbc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2b788a1-7dc5-4cb4-968b-994fe88707d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit.Quarterly pr...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech.The dollar ha...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim.The owners o...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits.British Airw...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq.Shares in UK...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>BT program to beat dialler scams.BT is introdu...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Spam e-mails tempt net shoppers.Computer users...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Be careful how you code.A new European directi...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>US cyber security chief resigns.The man making...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Losing yourself in online gaming.Online role p...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     label\n",
       "0     Ad sales boost Time Warner profit.Quarterly pr...  business\n",
       "1     Dollar gains on Greenspan speech.The dollar ha...  business\n",
       "2     Yukos unit buyer faces loan claim.The owners o...  business\n",
       "3     High fuel prices hit BA's profits.British Airw...  business\n",
       "4     Pernod takeover talk lifts Domecq.Shares in UK...  business\n",
       "...                                                 ...       ...\n",
       "2220  BT program to beat dialler scams.BT is introdu...      tech\n",
       "2221  Spam e-mails tempt net shoppers.Computer users...      tech\n",
       "2222  Be careful how you code.A new European directi...      tech\n",
       "2223  US cyber security chief resigns.The man making...      tech\n",
       "2224  Losing yourself in online gaming.Online role p...      tech\n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = text_dataset_from_directory_to_dataframe(dataset_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5033a19d-0722-482b-89f9-41e6576549dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the DataFrame rows\n",
    "shuff = df.sample(frac = 1, random_state=4473, ignore_index=True)\n",
    "\n",
    "# label encoding\n",
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "shuff['label_cat'] = labelencoder.fit_transform(shuff['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4abf021-17e5-43e3-9bf1-99863a35a9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'business', 1: 'entertainment', 2: 'politics', 3: 'sport', 4: 'tech'}\n"
     ]
    }
   ],
   "source": [
    "# for sanity\n",
    "class_name_list = list(labelencoder.classes_)\n",
    "class_dict = {}\n",
    "\n",
    "for class_name in class_name_list :\n",
    "    lbl_num = labelencoder.transform([class_name])[0]\n",
    "    class_dict[lbl_num] = class_name\n",
    "    \n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0db2c85-9b12-4dbe-8464-aa5c0655e83e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cae59760-b7df-4a55-bb67-5ca81d47f951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def custom_standardization(input_data, verbose= False):\n",
    "    # print original string\n",
    "    if verbose :\n",
    "        print(\"original string: \" ,input_data)\n",
    "    \n",
    "    # lowering\n",
    "    lowercase = input_data.lower()\n",
    "    \n",
    "    # print lowercase string\n",
    "    if verbose :\n",
    "        print('lower string: ', lowercase)\n",
    "    \n",
    "    \n",
    "    # clean the text\n",
    "    stripped = re.sub(\" #39;\", \"\\'\", lowercase)\n",
    "    stripped = re.sub(\" quot;\", \"\\\"\", stripped)\n",
    "    # remove stopword\n",
    "    # regex magic : r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*'\n",
    "    stripped = re.sub(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*',\"\", stripped)\n",
    "    \n",
    "    # print remove stopword string\n",
    "    if verbose :\n",
    "        print('Stopword removal: ', stripped)\n",
    "    \n",
    "    # strip punctuiation\n",
    "    stripped = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", stripped)\n",
    "    # remove double space\n",
    "    # two or more whitespace\n",
    "    stripped = re.sub(r\"(\\s\\s*)\", \" \", stripped)\n",
    "    stripped = re.sub(r\"(\\s+$)\", \"\", stripped)\n",
    "    \n",
    "    # tokenize\n",
    "    tokens = word_tokenize(stripped)\n",
    "\n",
    "    # print tokenize\n",
    "    if verbose :\n",
    "        print(\"toknize: \", tokens)\n",
    "    \n",
    "    # stemming\n",
    "    temp_cont = [porterStemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    # print stemmed\n",
    "    if verbose:\n",
    "        print(\"stemmed: \", temp_cont)\n",
    "    \n",
    "    porter_    = ' '.join(temp_cont)\n",
    "    return porter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26a237b8-6c98-45ac-9d03-b1763762e237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell:map_cleaning-text \n",
      "Execution Time : 18.35 s\n",
      "CPU times: total: 18.1 s\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c11_start = datetime.now()\n",
    "# clean text data\n",
    "clean_text = list(map(custom_standardization, shuff['text'].tolist()))\n",
    "shuff['clean_text'] = clean_text\n",
    "\n",
    "c11_duration = datetime.now() - c11_start\n",
    "print(\"cell:map_cleaning-text \\nExecution Time : {0:.2f} s\".format(c11_duration.total_seconds()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "effc1b15-89d8-4a9d-8dfc-5783e77a1253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_cat</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Looks and music to drive mobiles.Mobile phones...</td>\n",
       "      <td>tech</td>\n",
       "      <td>4</td>\n",
       "      <td>look music drive mobil mobil phone still enjoy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BT offers equal access to rivals.BT has moved ...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "      <td>bt offer equal access rival bt move pre empt p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High fuel prices hit BA's profits.British Airw...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "      <td>high fuel price hit ba profit british airway b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UK firms 'embracing e-commerce'.UK firms are e...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>uk firm embrac e commerc uk firm embrac intern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>News Corp makes $5.4bn Fox offer.News Corporat...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "      <td>news corp make 5 4bn fox offer news corpor see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>Microsoft seeking spyware trojan.Microsoft is ...</td>\n",
       "      <td>tech</td>\n",
       "      <td>4</td>\n",
       "      <td>microsoft seek spywar trojan microsoft investi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>Labour battle plan 'hides Blair'.The Tories ha...</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>labour battl plan hide blair tori accus toni b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Singer Sizzla jailed for swearing.Reggae star ...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>1</td>\n",
       "      <td>singer sizzla jail swear regga star sizzla who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>Blog reading explodes in America.Americans are...</td>\n",
       "      <td>tech</td>\n",
       "      <td>4</td>\n",
       "      <td>blog read explod america american becom avid b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Sir Paul rocks Super Bowl crowds.Sir Paul McCa...</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>1</td>\n",
       "      <td>sir paul rock super bowl crowd sir paul mccart...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text          label  \\\n",
       "0     Looks and music to drive mobiles.Mobile phones...           tech   \n",
       "1     BT offers equal access to rivals.BT has moved ...       business   \n",
       "2     High fuel prices hit BA's profits.British Airw...       business   \n",
       "3     UK firms 'embracing e-commerce'.UK firms are e...       politics   \n",
       "4     News Corp makes $5.4bn Fox offer.News Corporat...       business   \n",
       "...                                                 ...            ...   \n",
       "2220  Microsoft seeking spyware trojan.Microsoft is ...           tech   \n",
       "2221  Labour battle plan 'hides Blair'.The Tories ha...       politics   \n",
       "2222  Singer Sizzla jailed for swearing.Reggae star ...  entertainment   \n",
       "2223  Blog reading explodes in America.Americans are...           tech   \n",
       "2224  Sir Paul rocks Super Bowl crowds.Sir Paul McCa...  entertainment   \n",
       "\n",
       "      label_cat                                         clean_text  \n",
       "0             4  look music drive mobil mobil phone still enjoy...  \n",
       "1             0  bt offer equal access rival bt move pre empt p...  \n",
       "2             0  high fuel price hit ba profit british airway b...  \n",
       "3             2  uk firm embrac e commerc uk firm embrac intern...  \n",
       "4             0  news corp make 5 4bn fox offer news corpor see...  \n",
       "...         ...                                                ...  \n",
       "2220          4  microsoft seek spywar trojan microsoft investi...  \n",
       "2221          2  labour battl plan hide blair tori accus toni b...  \n",
       "2222          1  singer sizzla jail swear regga star sizzla who...  \n",
       "2223          4  blog read explod america american becom avid b...  \n",
       "2224          1  sir paul rock super bowl crowd sir paul mccart...  \n",
       "\n",
       "[2225 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b39b77c-6454-4b40-be72-4b44e5decd7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build TF-IDF SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73ae237a-2bbf-4ac7-9558-7b6bf8237a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Size :  2510\n",
      "cell:train_tf-idf \n",
      "Execution Time : 0.42 s\n",
      "CPU times: total: 406 ms\n",
      "Wall time: 417 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CELLNUM  : 13\n",
    "# CELLNAME : lucky-charm\n",
    "\n",
    "c13_start = datetime.now()\n",
    "# generate & fit\n",
    "vectorizer = TfidfVectorizer(min_df=0.01, \n",
    "                             max_df = 0.8, \n",
    "                             ngram_range=(1, 1))\n",
    "vectorizer.fit(shuff['clean_text'])\n",
    "dim_size = vectorizer.get_feature_names_out().shape[0]\n",
    "print(\"Vector Size : \", dim_size)\n",
    "c13_duration = datetime.now() - c13_start\n",
    "print(\"cell:train_tf-idf \\nExecution Time : {0:.2f} s\".format(c13_duration.total_seconds()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88460805-7348-4e7a-a430-c6d85f270436",
   "metadata": {
    "tags": []
   },
   "source": [
    "## K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56004713-19f6-436f-9fe4-01f6002b5970",
   "metadata": {},
   "outputs": [],
   "source": [
    "K5_fold = KFold(n_splits=5)\n",
    "fold = []\n",
    "# fold -> [[train_idex, val_index, test_index], ...,[train_idex, val_index, test_index]]\n",
    "\n",
    "for train_index, test_index in K5_fold.split(shuff['clean_text']):\n",
    "    val_index = test_index[int(len(test_index) / 2): ]\n",
    "    test_index = test_index[:int(len(test_index)/2)]\n",
    "#     print(\"TRAIN:\", train_index, \"VAL:\", val_index, \"TEST:\", test_index)\n",
    "    fold.append([train_index, val_index, test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8626ca-90a3-4e00-9248-269cfcad2ec6",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7f558f-3cd9-4261-8e4f-223c96a27c33",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build NN\n",
    "Build a NN from predetermined composition <br>\n",
    "Need `input_size` as a parameter          <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61f3d7d5-7770-41b7-83be-f1615edceb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# CELLNUM  : 21\n",
    "# CELLNAME : nana\n",
    "# Desc     : nn get it ?\n",
    "\n",
    "def build_nn(input_size:int):\n",
    "    input_layer = layers.Input(shape=(input_size,))\n",
    "\n",
    "    hdn  = layers.Dense(900, activation='selu') (input_layer)\n",
    "    hdn = layers.BatchNormalization(momentum=0.99, epsilon=0.0001)(hdn)\n",
    "    hdn  = layers.Dense(600, activation='elu') (hdn)\n",
    "    hdn = layers.BatchNormalization(momentum=0.99, epsilon=0.0001)(hdn)\n",
    "    hdn  = layers.Dense(900, activation='selu') (hdn)\n",
    "    hdn  = layers.Dense(700, activation='selu') (hdn)\n",
    "\n",
    "    # using logits so this is how the output look\n",
    "    predictions = layers.Dense(20, name=\"predictions\")(hdn)\n",
    "    \n",
    "    model = tf.keras.Model(input_layer, predictions)\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    # Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "    model.compile(loss= loss,\n",
    "              optimizer=\"adam\", \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f32105-67e4-4484-aae1-69fc88015f77",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Metrics for ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ab8de12-dd4b-4153-9b5c-17834a714fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to classification_report homebrew\n",
    "def _report_classification(confusion_matrix, class_name= class_dict, as_df=True) :\n",
    "    # class_name -> a dict with int as key and str as value\n",
    "    \n",
    "    kf_tbl = {}\n",
    "    for i in range(confusion_matrix.shape[0]) :\n",
    "        c_name = class_name[i]\n",
    "        kf_tbl[c_name] = {}\n",
    "        # TP \n",
    "        kf_tbl[c_name][\"TP\"] = confusion_matrix[i,i]\n",
    "        # FN\n",
    "        # baris koma belakang\n",
    "        kf_tbl[c_name][\"FN\"] = np.sum(confusion_matrix[i, :]) - confusion_matrix[i,i]\n",
    "        # FP\n",
    "        # klo liat kolom koma depan\n",
    "        kf_tbl[c_name][\"FP\"] = np.sum(confusion_matrix[: ,i]) - confusion_matrix[i,i]\n",
    "        # FN\n",
    "        kf_tbl[c_name][\"TN\"] = np.sum(confusion_matrix) - (kf_tbl[c_name][\"TP\"] + kf_tbl[c_name][\"FN\"] + kf_tbl[c_name][\"FP\"])\n",
    "        # Precision\n",
    "        kf_tbl[c_name][\"Precision\"] = np.nan_to_num(kf_tbl[c_name][\"TP\"]/(kf_tbl[c_name][\"TP\"] + kf_tbl[c_name][\"FP\"]))\n",
    "\n",
    "        # Recall\n",
    "        kf_tbl[c_name][\"Recall\"] = np.nan_to_num((kf_tbl[c_name][\"TP\"]/(kf_tbl[c_name][\"TP\"] + kf_tbl[c_name][\"FN\"])))\n",
    "        # f1-score per-class\n",
    "        _temp = (kf_tbl[c_name][\"Precision\"]* kf_tbl[c_name][\"Recall\"])\n",
    "        _temp = _temp/(kf_tbl[c_name][\"Precision\"] + kf_tbl[c_name][\"Recall\"])\n",
    "        _temp = np.nan_to_num(_temp)\n",
    "        kf_tbl[c_name][\"f1-score\"] = np.nan_to_num(2*_temp)\n",
    "    if as_df : \n",
    "        t_tbl = {\"labels\" : [],\n",
    "                 \"TP\"     : [],\n",
    "                 \"FN\"     : [],\n",
    "                 \"FP\"     : [],\n",
    "                 \"TN\"     : [],\n",
    "                 \"Precision\" : [],\n",
    "                 \"Recall\"    : [],\n",
    "                 \"f1-score\"  : []\n",
    "                }\n",
    "        for key in list(kf_tbl.keys()) :\n",
    "            t_tbl['labels'].append(key)\n",
    "            t_tbl['TP'].append(kf_tbl[key]['TP'])\n",
    "            t_tbl['FN'].append(kf_tbl[key]['FN'])\n",
    "            t_tbl['FP'].append(kf_tbl[key]['FP'])\n",
    "            t_tbl['TN'].append(kf_tbl[key]['TN'])\n",
    "            t_tbl['Precision'].append(kf_tbl[key]['Precision'])\n",
    "            t_tbl['Recall'].append(kf_tbl[key]['Recall'])\n",
    "            t_tbl['f1-score'].append(kf_tbl[key]['f1-score'])\n",
    "        df = pd.DataFrame.from_dict(t_tbl)\n",
    "        df = df.set_index('labels')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    return kf_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6582911-e9ac-4910-b547-23bb70b8e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert data from _report_classification to macro-f1 and micro-f1 and weighted-f1\n",
    "# support = tp + fn\n",
    "def get_f1(cls_report) :\n",
    "    cls_report_type = type(cls_report)\n",
    "    if cls_report_type is dict :\n",
    "        cls_num = len(list(cls_report.keys()))\n",
    "        cls_keys = list(cls_report.keys())\n",
    "        \n",
    "        # macro\n",
    "        # get all f1-score then just average it to cls_num\n",
    "        _f1_list = []\n",
    "        for key in cls_keys :\n",
    "            _f1_list.append(cls_report[key]['f1-score'])\n",
    "        _macro_f1 = sum(_f1_list) / cls_num\n",
    "        _f1_list = None\n",
    "        \n",
    "        # weigthed\n",
    "        # support_proportion = support / sum(support)\n",
    "        # sum(f1*support_proportion)\n",
    "        _f1_list = []\n",
    "        _sum_support = 0\n",
    "        for key in cls_keys :\n",
    "            _support = cls_report[key]['TP'] + cls_report[key]['FN']\n",
    "            _f1_list.append(cls_report[key]['f1-score'] * _support)\n",
    "            _sum_support += _support\n",
    "        _weighted_f1 = sum(_f1_list) / _sum_support\n",
    "        _f1_list = None\n",
    "                        \n",
    "        # micro\n",
    "        # all_class_TP FP  amnd FN\n",
    "        # using that just count f1 normally\n",
    "        _sum_TP = 0\n",
    "        _sum_FP = 0\n",
    "        _sum_FN = 0\n",
    "        for key in cls_keys :\n",
    "            _sum_TP += cls_report[key]['TP']\n",
    "            _sum_FP += cls_report[key]['FP']\n",
    "            _sum_FN += cls_report[key]['FN']\n",
    "        _micro_f1 = _sum_TP / (_sum_TP + (0.5*(_sum_FP + _sum_FN)))\n",
    "                        \n",
    "        rslt = {'f1' : {\n",
    "                'micro'    : _micro_f1,\n",
    "                'macro'    : _macro_f1,\n",
    "                'weighted' : _weighted_f1}\n",
    "              }\n",
    "        return rslt\n",
    "    elif cls_report_type is pd.core.frame.DataFrame :\n",
    "        cls_num = cls_report.shape[0]\n",
    "        \n",
    "        # macro\n",
    "        _macro_f1 = sum(cls_report['f1-score'].tolist()) / len(cls_report['f1-score'].tolist())\n",
    "        \n",
    "        # weighted\n",
    "        # support = tp + fn\n",
    "        _cls_TP = cls_report['TP'].tolist()\n",
    "        _cls_FN = cls_report['FN'].tolist()\n",
    "        _cls_f1 = cls_report['f1-score'].tolist()\n",
    "        \n",
    "        _support = [_cls_TP[i] + _cls_FN[i] for i in range(len(_cls_TP))]\n",
    "        _sum_support = sum(_support)\n",
    "        \n",
    "        # sum(f1[i] * (support[i] / sum(support)))\n",
    "        _weighted_f1 = sum([_cls_f1[i] * (_support[i] / _sum_support) for i in range(len(_cls_f1))])\n",
    "        \n",
    "        # micro\n",
    "        _sum_TP = sum(cls_report['TP'].tolist())\n",
    "        _sum_FP = sum(cls_report['FP'].tolist())\n",
    "        _sum_FN = sum(cls_report['FN'].tolist())\n",
    "        _micro_f1 = _sum_TP / (_sum_TP + (0.5*(_sum_FP + _sum_FN)))\n",
    "        \n",
    "        rslt = {'f1' : {\n",
    "                'micro'    : _micro_f1,\n",
    "                'macro'    : _macro_f1,\n",
    "                'weighted' : _weighted_f1}\n",
    "              }\n",
    "        return rslt\n",
    "    else :\n",
    "        err = {'f1' : {\n",
    "                'micro'    : -4473,\n",
    "                'macro'    : -4473,\n",
    "                'weighted' : -4473}\n",
    "              }\n",
    "        \n",
    "        return err\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4c7ae48-a59e-4763-91bc-1597ed1f5320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _average_dataframe(list_dframe: list) :\n",
    "    for i in range(len(list_dframe)) :\n",
    "        if i == 0 :\n",
    "            f_avg = list_dframe[i]\n",
    "        else :\n",
    "            f_avg = f_avg.add(list_dframe[i])\n",
    "\n",
    "    # divide by amount of fold\n",
    "    f_avg = f_avg.div(len(list_dframe))\n",
    "\n",
    "    # round down\n",
    "    f_avg['TP'] = f_avg['TP'].astype('int')\n",
    "    f_avg['FN'] = f_avg['FN'].astype('int')\n",
    "    f_avg['FP'] = f_avg['FP'].astype('int')\n",
    "    f_avg['TN'] = f_avg['TN'].astype('int')\n",
    "    \n",
    "    # return an average of all dataframe\n",
    "    return f_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3778e50-1c02-4525-9926-21cc3f23708e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "Evaluate the f1-measure and acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be6745d-6fcf-42f9-8f7f-fb63eb59a14a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function to Evaluate Vanilla Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36c8315e-88a5-4a3c-b117-f5e04aa13297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _eval_control(save_file=False) :\n",
    "\n",
    "    i = 1\n",
    "    t_res = []\n",
    "    t_loss = []\n",
    "    t_acc =[]\n",
    "    \n",
    "    list_dataframe = []\n",
    "    for train_index, val_index, test_index in fold :\n",
    "        f_cstart = datetime.now()\n",
    "        # clear session _del model from memory\n",
    "        tf.keras.backend.clear_session()\n",
    "    \n",
    "        X_train = vectorizer.transform(shuff['clean_text'][train_index]).toarray()\n",
    "        X_val = vectorizer.transform(shuff['clean_text'][val_index]).toarray()\n",
    "        X_test = vectorizer.transform(shuff['clean_text'][test_index]).toarray()\n",
    "        \n",
    "        \n",
    "        y_train = shuff['label_cat'][train_index]\n",
    "        y_val = shuff['label_cat'][val_index]\n",
    "        y_test = shuff['label_cat'][test_index]\n",
    "        \n",
    "        nn_name = \"single_control_{}\".format(i)\n",
    "        nn_model = build_nn(input_size=dim_size)\n",
    "        nn_model._name = nn_name\n",
    "        \n",
    "        # train - fit\n",
    "        fit_history = nn_model.fit(X_train, \n",
    "                                    y_train, \n",
    "                                    epochs=100, \n",
    "                                    batch_size=75, \n",
    "                                    validation_data = (X_val, y_val),\n",
    "                                    verbose=0)\n",
    "        # eval\n",
    "        # print(\"Evaluate on test data \", i)\n",
    "        results = nn_model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "        # print(nn_model.metrics_names)\n",
    "        print(\"test loss, test acc:\", results)\n",
    "        pred = nn_model.predict(X_test, verbose=0)\n",
    "        pred = np.argmax(pred, axis=1)\n",
    "        result_df = _report_classification(confusion_matrix(y_test, pred))\n",
    "        result_f1 = get_f1(result_df)\n",
    "        print(\"fold {} f1-macro : {}\".format(i, result_f1['f1']['macro']))\n",
    "        t_res.append(result_f1['f1']['macro'])\n",
    "        t_loss.append(results[0])\n",
    "        t_acc.append(results[1])\n",
    "        \n",
    "        list_dataframe.append(result_df)\n",
    "                \n",
    "        # delete\n",
    "        X_train, X_val,X_test = None, None, None\n",
    "        y_train, y_val,y_test = None, None, None\n",
    "        \n",
    "        f_cdur = datetime.now() - f_cstart\n",
    "        print(\"func:eval_model on fold {} \\nExecution Time : {:.2f} s\".format(i , f_cdur.total_seconds()))\n",
    "        print()\n",
    "                \n",
    "        i += 1\n",
    "        \n",
    "    result_avg = _average_dataframe(list_dataframe)\n",
    "    \n",
    "    d_result = {'result' : result_avg,\n",
    "                'f1-macro' : sum(t_res) / len(t_res),\n",
    "                'loss' : sum(t_loss) / len(t_loss),\n",
    "                'acc'  : sum(t_acc) / len(t_acc)}\n",
    "    \n",
    "    print('control result')\n",
    "    print(d_result)\n",
    "    return d_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b8aaf1-9076-4879-96cf-e680f6fc7a8c",
   "metadata": {},
   "source": [
    "### Control Experiment Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "189ff6c1-7a3d-493e-8825-791cc9b77dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss, test acc: [3.372105598449707, 0.9324324131011963]\n",
      "fold 1 f1-macro : 0.9306344377535535\n",
      "func:eval_model on fold 1 \n",
      "Execution Time : 30.25 s\n",
      "\n",
      "test loss, test acc: [1.6693100929260254, 0.9504504799842834]\n",
      "fold 2 f1-macro : 0.9442879112778323\n",
      "func:eval_model on fold 2 \n",
      "Execution Time : 28.24 s\n",
      "\n",
      "test loss, test acc: [0.587522566318512, 0.9819819927215576]\n",
      "fold 3 f1-macro : 0.9819615954647645\n",
      "func:eval_model on fold 3 \n",
      "Execution Time : 27.78 s\n",
      "\n",
      "test loss, test acc: [1.0010404586791992, 0.9819819927215576]\n",
      "fold 4 f1-macro : 0.9820274841289685\n",
      "func:eval_model on fold 4 \n",
      "Execution Time : 27.90 s\n",
      "\n",
      "test loss, test acc: [0.5009213089942932, 0.977477490901947]\n",
      "fold 5 f1-macro : 0.9772405051801714\n",
      "func:eval_model on fold 5 \n",
      "Execution Time : 28.43 s\n",
      "\n",
      "control result\n",
      "{'result':                TP  FN  FP   TN  Precision    Recall  f1-score\n",
      "labels                                                       \n",
      "business       47   2   1  171   0.966711  0.950302  0.957909\n",
      "entertainment  35   1   1  183   0.954333  0.959723  0.956883\n",
      "politics       42   1   2  175   0.945383  0.976140  0.960417\n",
      "sport          51   1   0  169   0.988727  0.981660  0.984990\n",
      "tech           38   2   1  180   0.961667  0.951047  0.955953, 'f1-macro': 0.9632303867610581, 'loss': 1.4261800050735474, 'acc': 0.9648648738861084}\n",
      "AVERAGE PRECISION :  0.9633642332946989\n",
      "AVERAGE RECALL :  0.9637745072310094\n"
     ]
    }
   ],
   "source": [
    "control_measurement = _eval_control(save_file=False)\n",
    "\n",
    "print(\"AVERAGE PRECISION : \", control_measurement['result']['Precision'].mean())\n",
    "print(\"AVERAGE RECALL : \", control_measurement['result']['Recall'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b708fe-fcaf-48ec-a138-29bdd2dc7281",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function to Compare with other alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad5559b8-80b3-4c43-abfb-253fefc0b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _eval_svm(save_file=False) :\n",
    "    i = 1\n",
    "    t_res = []\n",
    "    list_dataframe = []\n",
    "    for train_index, val_index, test_index in fold :\n",
    "        f_svmstart = datetime.now()\n",
    "        \n",
    "        \n",
    "        X_train = vectorizer.transform(shuff['clean_text'][train_index]).toarray()\n",
    "        X_val = vectorizer.transform(shuff['clean_text'][val_index]).toarray()\n",
    "        X_test = vectorizer.transform(shuff['clean_text'][test_index]).toarray()\n",
    "\n",
    "\n",
    "        y_train = shuff['label_cat'][train_index].tolist()\n",
    "        y_val = shuff['label_cat'][val_index].tolist()\n",
    "        y_test = shuff['label_cat'][test_index].tolist()\n",
    "        \n",
    "        svc = svm.SVC(kernel='linear',decision_function_shape='ovr')\n",
    "        svc.fit(X_train, y_train)\n",
    "    \n",
    "        pred = svc.predict(X_test)\n",
    "        \n",
    "        result_df = _report_classification(confusion_matrix(y_test, pred))\n",
    "        \n",
    "        list_dataframe.append(result_df)\n",
    "        # delete\n",
    "        X_train, X_val,X_test = None, None, None\n",
    "        y_train, y_val,y_test = None, None, None\n",
    "        \n",
    "        print('finish fold-{}'.format(i))\n",
    "        i += 1\n",
    "    # average all fold\n",
    "    result_avg = _average_dataframe(list_dataframe)\n",
    "    result_f1 = get_f1(result_avg)\n",
    "\n",
    "    f_svmduration = datetime.now() - f_svmstart\n",
    "    print(\"func:evaluate_svm \\nExecution Time : {:2f} s\".format(f_svmduration.total_seconds()))\n",
    "    return {'result' : result_avg,\n",
    "            'f1'     : result_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cf9eb40-63e8-4605-afa6-b0838ec71961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish fold-1\n",
      "finish fold-2\n",
      "finish fold-3\n",
      "finish fold-4\n",
      "finish fold-5\n",
      "func:evaluate_svm \n",
      "Execution Time : 2.997329 s\n",
      "{'result':                TP  FN  FP   TN  Precision    Recall  f1-score\n",
      "labels                                                       \n",
      "business       47   2   1  170   0.961946  0.951524  0.956616\n",
      "entertainment  36   0   0  184   0.981818  0.980960  0.981094\n",
      "politics       42   1   1  176   0.958418  0.976852  0.967151\n",
      "sport          52   0   0  169   0.988517  0.996429  0.992401\n",
      "tech           38   1   0  181   0.979884  0.970808  0.975064, 'f1': {'f1': {'micro': 0.9862385321100917, 'macro': 0.9744652674364683, 'weighted': 0.9744905251507652}}}\n",
      "AVERAGE PRECISION :  0.9741167085826031\n",
      "AVERAGE RECALL :  0.9753144304296327\n"
     ]
    }
   ],
   "source": [
    "svm_result = _eval_svm(save_file=False)\n",
    "print(svm_result)\n",
    "print(\"AVERAGE PRECISION : \", svm_result['result']['Precision'].mean())\n",
    "print(\"AVERAGE RECALL : \", svm_result['result']['Recall'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "377f1ca3-9140-4a75-8caf-10e1fd1b0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _eval_nb(save_file=False) :\n",
    "    i = 1\n",
    "    t_res = []\n",
    "    list_dataframe = []\n",
    "    for train_index, val_index, test_index in fold :\n",
    "        f_nbstart = datetime.now()\n",
    "        \n",
    "        \n",
    "        X_train = vectorizer.transform(shuff['clean_text'][train_index]).toarray()\n",
    "        X_val = vectorizer.transform(shuff['clean_text'][val_index]).toarray()\n",
    "        X_test = vectorizer.transform(shuff['clean_text'][test_index]).toarray()\n",
    "\n",
    "\n",
    "        y_train = shuff['label_cat'][train_index]\n",
    "        y_val = shuff['label_cat'][val_index]\n",
    "        y_test = shuff['label_cat'][test_index]\n",
    "        \n",
    "        mb_nb = MultinomialNB(alpha = 0.6)\n",
    "        mb_nb.fit(X_train, y_train)\n",
    "    \n",
    "        pred = mb_nb.predict(X_test)\n",
    "        \n",
    "        result_df = _report_classification(confusion_matrix(y_test, pred))\n",
    "        \n",
    "        list_dataframe.append(result_df)\n",
    "        # delete\n",
    "        X_train, X_val,X_test = None, None, None\n",
    "        y_train, y_val,y_test = None, None, None\n",
    "        \n",
    "        print('finish fold-{}'.format(i))\n",
    "        i += 1\n",
    "    # average all fold\n",
    "    result_avg = _average_dataframe(list_dataframe)\n",
    "    result_f1 = get_f1(result_avg)\n",
    "\n",
    "    f_nbduration = datetime.now() - f_nbstart\n",
    "    print(\"func:evaluate_naivebayes \\nExecution Time : {:2f} s\".format(f_nbduration.total_seconds()))\n",
    "    return {'result' : result_avg,\n",
    "            'f1'     : result_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ad41738-20fc-4190-9804-f6062f852dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish fold-1\n",
      "finish fold-2\n",
      "finish fold-3\n",
      "finish fold-4\n",
      "finish fold-5\n",
      "func:evaluate_naivebayes \n",
      "Execution Time : 0.485442 s\n",
      "{'result':                TP  FN  FP   TN  Precision    Recall  f1-score\n",
      "labels                                                       \n",
      "business       47   1   2  170   0.958984  0.968059  0.963367\n",
      "entertainment  35   1   0  184   0.988342  0.958754  0.973202\n",
      "politics       42   1   1  177   0.971013  0.970799  0.970346\n",
      "sport          52   0   0  169   0.992792  0.996429  0.994594\n",
      "tech           38   1   1  180   0.955652  0.968682  0.961854, 'f1': {'f1': {'micro': 0.981651376146789, 'macro': 0.9726725014236685, 'weighted': 0.9735455827966392}}}\n",
      "AVERAGE PRECISION :  0.9733564675365729\n",
      "AVERAGE RECALL :  0.9725447439267587\n"
     ]
    }
   ],
   "source": [
    "nb_result = _eval_nb()\n",
    "print(nb_result)\n",
    "\n",
    "print(\"AVERAGE PRECISION : \", nb_result['result']['Precision'].mean())\n",
    "print(\"AVERAGE RECALL : \", nb_result['result']['Recall'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
